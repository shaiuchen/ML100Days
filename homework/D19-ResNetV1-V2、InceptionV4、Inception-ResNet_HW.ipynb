{"cells":[{"cell_type":"markdown","metadata":{"id":"DTOXyarn85gM"},"source":["## 『本次練習內容』\n","#### 學習如何搭建 Residual Block\n","####  學習如何搭建Inception-ResNet中的 Inception Block"]},{"cell_type":"markdown","metadata":{"id":"wgQZ-4sf85gO"},"source":["## 『本次練習目的』\n","  #### 了解 Residual Block原理\n","  #### 了解如何結合Inception 與 Residual概念"]},{"cell_type":"markdown","metadata":{"id":"KtVX4XE685gP"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"a8ujre2y85gQ"},"source":["## Part1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1QrYF4Jl85gQ"},"outputs":[],"source":["import numpy as np\n","from keras.models import Model\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.layers import Input\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import GlobalMaxPooling2D\n","from keras.layers import GlobalAveragePooling2D\n","from keras import backend as K\n","from keras import layers\n","from keras.layers import BatchNormalization\n","from keras.layers import Activation\n","from keras.layers import Concatenate\n","from keras.layers import Lambda"]},{"cell_type":"markdown","metadata":{"id":"AQpoDt7B85gS"},"source":["![Incpeiton](ResNet_Structure.png)"]},{"cell_type":"markdown","metadata":{"id":"hKQwRLCu85gT"},"source":["## ResNetV1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wQSe5QDk85gT"},"outputs":[],"source":["def Residual_block(input_tensor, kernel_size, filters, stage, block):\n","    filters1, filters2, filters3 = filters\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","\n","    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n","    x = BatchNormalization(axis=3, name=bn_name_base + '2a')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters2, kernel_size,\n","               padding='same', name=conv_name_base + '2b')(x)\n","    x = BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n","\n","\n","    x = layers.add([x, input_tensor])\n","    x = Activation('relu')(x)\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"F8-zB7H285gU"},"source":["## 參考ResNetV1 搭建 ResNetV2版本的Residual Block"]},{"cell_type":"code","source":["def Residual_block_v2(input_tensor, kernel_size, filters, stage, block):\n","    filters1, filters2, filters3 = filters\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","\n","    # 第一层：BN -> ReLU -> 1x1卷积\n","    x = BatchNormalization(axis=3, name=bn_name_base + '2a')(input_tensor)\n","    x = Activation('relu')(x)\n","    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(x)\n","\n","    # 第二层：BN -> ReLU -> 3x3卷积\n","    x = BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n","    x = Activation('relu')(x)\n","    x = Conv2D(filters2, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n","\n","    # 第三层：BN -> ReLU（如果有第三层卷积）\n","    # 若有第三层可在这里添加 (同样需要BN -> ReLU -> Conv2D)\n","    # x = BatchNormalization(axis=3, name=bn_name_base + '2c')(x)\n","    # x = Activation('relu')(x)\n","    # x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n","\n","    # 在与identity branch相加之前，再做一次BN处理\n","    #x = BatchNormalization(axis=3, name=bn_name_base + '2c')(x)\n","\n","    # 跳跃连接：加上input_tensor，最后不使用ReLU\n","    x = layers.add([x, input_tensor])\n","\n","    return x"],"metadata":{"id":"NvVpjP83_93R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qwU3-VK685gV"},"source":["## 試試看自己設計一個先壓縮再回放的V2 Block"]},{"cell_type":"code","source":["def Residual_block_v2(input_tensor, kernel_size, stage, block, reduce=96, output_size=128):\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","\n","    # 1. 压缩部分：BN -> ReLU -> 1x1卷积 (减少通道数到 reduce 大小)\n","    x = BatchNormalization(axis=3, name=bn_name_base + '2a')(input_tensor)\n","\n","    x = Conv2D((reduce,reduce), (1, 1), name=conv_name_base + '2a')(x)\n","    x = Activation('relu')(x)\n","\n","    # 2. 核心卷积：BN -> ReLU -> kernel_size 卷积 (保持 reduce 大小)\n","    x = BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n","    x = Activation('relu')(x)\n","    x = Conv2D(reduce, kernel_size, padding='same', name=conv_name_base + '2b')(x)\n","\n","    # 3. 回放部分：BN -> ReLU -> 1x1卷积 (将通道数恢复到 output_size)\n","    x = BatchNormalization(axis=3, name=bn_name_base + '2c')(x)\n","    x = Activation('relu')(x)\n","    x = Conv2D(output_size, (1, 1), name=conv_name_base + '2c')(x)\n","\n","    # 4. 在与identity branch相加之前，再做一次BN处理\n","    x = BatchNormalization(axis=3, name=bn_name_base + '2d')(x)\n","\n","    # 跳跃连接：加上input_tensor，最后不使用ReLU\n","    x = Add()([x, input_tensor])\n","\n","    return x\n"],"metadata":{"id":"7g65Te6pIbu1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mjGf_MbZ85gV"},"outputs":[],"source":["def Residual_block_v2(input_tensor, kernel_size, stage, block,reduce=96,ouput_size=128):\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MQWMj4ez85gW"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"BDqYdYks85gW"},"source":["## Part2"]},{"cell_type":"markdown","metadata":{"id":"tfa8Vx5iJbZU"},"source":["## Incpetion Block-A"]},{"cell_type":"markdown","metadata":{"id":"xbuyi79mJbZX"},"source":["![Incpeiton](Inception-ResNet-A.png)"]},{"cell_type":"markdown","metadata":{"id":"3GI24k24JbZa"},"source":["## Incpetion Block-B"]},{"cell_type":"markdown","metadata":{"id":"Ge28e58BJbZd"},"source":["![Incpeiton](Inception-ResNet-B.png)"]},{"cell_type":"markdown","metadata":{"id":"aMz1WNBsJbZg"},"source":["## Incpetion Block-C"]},{"cell_type":"markdown","metadata":{"id":"A4lY1HV6JbZj"},"source":["![Incpeiton](Inception-ResNet-C.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t9IKAa_4JbZ1"},"outputs":[],"source":["def Conv2d_bn(x,filters,kernel_size,padding='same',strides=(1, 1),normalizer=True,activation='relu',name=None):\n","\n","    if name is not None:\n","        conv_name = name + '_conv'\n","        bn_name = name + '_bn'\n","        act_name = name + '_act'\n","    else:\n","        conv_name = None\n","        bn_name = None\n","        act_name = None\n","    if K.image_data_format() == 'channels_first':\n","        bn_axis = 1\n","    else:\n","        bn_axis = 3\n","    x = Conv2D(\n","            filters, kernel_size,\n","            strides=strides, padding=padding,\n","            use_bias=False, name=conv_name)(x)\n","    if normalizer:\n","        x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n","    if activation:\n","        x = Activation(activation, name=act_name)(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7iVPJQkJbZ-"},"outputs":[],"source":["def Residual_block(input_tensor, kernel_size, filters, stage, block):\n","    filters1, filters2, filters3 = filters\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","\n","    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n","    x = BatchNormalization(axis=3, name=bn_name_base + '2a')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters2, kernel_size,\n","               padding='same', name=conv_name_base + '2b')(x)\n","    x = BatchNormalization(axis=3, name=bn_name_base + '2b')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n","    x = BatchNormalization(axis=3, name=bn_name_base + '2c')(x)\n","\n","    x = layers.add([x, input_tensor])\n","    x = Activation('relu')(x)\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"M0BEkO7VJbaI"},"source":["## 參考上方Residual_block搭建 Inception-ResNet中的Inception Block"]},{"cell_type":"code","source":["pip install --upgrade keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":528},"id":"eRk9qo9Ue5Mi","executionInfo":{"status":"ok","timestamp":1724085207844,"user_tz":-480,"elapsed":8023,"user":{"displayName":"TMU陳筱蓁","userId":"00816295719701166481"}},"outputId":"36c47fc6-5855-4b98-bcfa-f557d7f80a91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n","Collecting keras\n","  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.4.1\n","    Uninstalling keras-3.4.1:\n","      Successfully uninstalled keras-3.4.1\n","Successfully installed keras-3.5.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["keras"]},"id":"854a8c31c1a140cdb0c100cf37943f66"}},"metadata":{}}]},{"cell_type":"code","source":["!pip install --upgrade tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TSX5xYse-cUi","executionInfo":{"status":"ok","timestamp":1724160534378,"user_tz":-480,"elapsed":5858,"user":{"displayName":"TMU陳筱蓁","userId":"00816295719701166481"}},"outputId":"3c7e1136-3641-4719-df54-66ddd9308998"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","from tensorflow.keras.layers import Input, Conv2D, Concatenate, Lambda, Activation\n","from tensorflow.keras import backend as K"],"metadata":{"id":"qq45xljW9Uwf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Input, Conv2D, Concatenate, Lambda, Activation, Layer # Import Layer"],"metadata":{"id":"en34QPLL_3VS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras.backend as K"],"metadata":{"id":"Xp0Rp4RDSd2-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def inception_resnet_block(x, scale, block_type, activation='relu'):\n","    '''scale: scaling factor to scale the residuals (i.e., the output of\n","            passing `x` through an inception module) before adding them\n","            to the shortcut branch. Let `r` be the output from the residual branch,\n","            the output of this block will be `x + scale * r`.(簡單來說就是控制Residual branch的比例)'''\n","    if block_type == 'Incpetion_Block-A':\n","        branch_0 = Conv2D(32, (1,1), padding='same', name='Block-A_branch_0')(x)\n","        branch_1 = Conv2D(32, (1,1), padding='same', name='Block-A_branch_1_1')(x)\n","        branch_1 = Conv2D(32, (3,3), padding='same', name='Block-A_branch_1_2')(branch_1)\n","        branch_2 = Conv2D(32, (1,1), padding='same', name='Block-A_branch_2_1')(x)\n","        branch_2 = Conv2D(48, (3,3), padding='same', name='Block-A_branch_2_2')(branch_2)\n","        branch_2 = Conv2D(64, (3,3), padding='same', name='Block-A_branch_2_3')(branch_2)\n","        branches = [branch_0, branch_1, branch_2]\n","\n","    elif block_type == 'Incpetion_Block-B':\n","        branch_0 = Conv2D(192, (1,1), padding='same', name='Block-B_branch_0')(x)\n","        branch_1 = Conv2D(128, (1,1), padding='same', name='Block-B_branch_1_1')(x)\n","        branch_1 = Conv2D(160, (1,7), padding='same', name='Block-B_branch_1_2')(branch_1)\n","        branch_1 = Conv2D(192, (7,1), padding='same', name='Block-B_branch_1_3')(branch_1)\n","        branches = [branch_0, branch_1]\n","\n","    elif block_type == 'Incpetion_Block-C':\n","        branch_0 = Conv2D(192, (1,1), padding='same', name='Block-C_branch_0')(x)\n","        branch_1 = Conv2D(192, (1,1), padding='same', name='Block-C_branch_1_1')(x)\n","        branch_1 = Conv2D(192, (1,3), padding='same', name='Block-C_branch_1_2')(branch_1)\n","        branch_1 = Conv2D(192, (3,1), padding='same', name='Block-C_branch_1_3')(branch_1)\n","        branches = [branch_0, branch_1]\n","\n","    else:\n","        raise ValueError('Unknown Inception-ResNet block type. '\n","                         'Expects \"block35\", \"block17\" or \"block8\", '\n","                         'but got: ' + str(block_type))\n","\n","    mixed = Concatenate(axis=3)(branches)\n","\n","    # Wrap the TensorFlow operation in a Keras Layer\n","    class Conv2d_bn(Layer):\n","        def __init__(self, filters, kernel_size, activation=None, **kwargs):\n","            super(Conv2d_bn, self).__init__(**kwargs)\n","            self.filters = filters\n","            self.kernel_size = kernel_size\n","            self.activation = activation\n","\n","        def build(self, input_shape):\n","            self.conv = Conv2D(self.filters, self.kernel_size, padding='same')\n","            self.bn = BatchNormalization()\n","            self.act = Activation(self.activation) if self.activation else None\n","            super(Conv2d_bn, self).build(input_shape)  # Be sure to call this at the end\n","\n","        def call(self, inputs):\n","            x = self.conv(inputs)\n","            return x\n","\n","        '''確保輸入跟輸出深度相同'''\n","    up = Conv2d_bn(mixed,K.shape(x)[3],1,activation=None)\n","\n","    '''導入殘差結構，並給予權重'''\n","    x = Lambda(lambda inputs, scale: inputs[0]+inputs[1] * scale, ##提示inputs[0]、inputs[1]\n","               output_shape=K.shape(x)[1:],\n","               arguments={'scale': scale},)([x,up])\n","\n","    if activation is not None:\n","        x = Activation(activation)(x)\n","    return x\n"],"metadata":{"id":"laCpmJ1CL7zQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip show keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96Yb6HGIQP_8","executionInfo":{"status":"ok","timestamp":1724166393243,"user_tz":-480,"elapsed":2749,"user":{"displayName":"TMU陳筱蓁","userId":"00816295719701166481"}},"outputId":"2dd81eb8-63d8-47ac-81d5-21a91306ad42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: keras\n","Version: 3.4.1\n","Summary: Multi-backend Keras.\n","Home-page: https://github.com/keras-team/keras\n","Author: Keras team\n","Author-email: keras-users@googlegroups.com\n","License: Apache License 2.0\n","Location: /usr/local/lib/python3.10/dist-packages\n","Requires: absl-py, h5py, ml-dtypes, namex, numpy, optree, packaging, rich\n","Required-by: tensorflow\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XJjxq9lWJbaN"},"outputs":[],"source":["def inception_resnet_block(x, scale, block_type, activation='relu'):\n","    '''scale: scaling factor to scale the residuals (i.e., the output of\n","            passing `x` through an inception module) before adding them\n","            to the shortcut branch. Let `r` be the output from the residual branch,\n","            the output of this block will be `x + scale * r`.(簡單來說就是控制Residual branch的比例)'''\n","    if block_type == 'Incpetion_Block-A':\n","        branch_0 = Conv2D(32, (1,1), strides = 1,  padding='same', name='Block-A_branch_0')(x)\n","        branch_1 = Conv2D(32, (1,1), strides = 1,padding='same', name='Block-A_branch_1_1')(x)\n","        branch_1 = Conv2D(32, (3,3), strides = 1,padding='same', name='Block-A_branch_1_2')(branch_1)\n","        branch_2 = Conv2D(32, (1,1), strides = 1,padding='same', name='Block-A_branch_2_1')(x)\n","        branch_2 = Conv2D(48, (3,3), strides = 1,padding='same', name='Block-A_branch_2_2')(branch_2)\n","        branch_2 = Conv2D(64, (3,3), strides = 1,padding='same', name='Block-A_branch_2_3')(branch_2)\n","        branches = [branch_0, branch_1, branch_2]\n","\n","    elif block_type == 'Incpetion_Block-B':\n","        branch_0 = Conv2D(192, (1,1), strides = 1,padding='same', name='Block-B_branch_0')(x)\n","        branch_1 = Conv2D(192, (7,1), strides = 1,padding='same', name='Block-B_branch_1_1')(x)\n","        branch_1 = Conv2D(160, (1,7), strides = 1,padding='same', name='Block-B_branch_1_2')(branch_1)\n","        branch_1 = Conv2D(128, (1,1), strides = 1,padding='same', name='Block-B_branch_1_3')(branch_1)\n","        branches = [branch_0, branch_1]\n","\n","    elif block_type == 'Incpetion_Block-C':\n","        branch_0 = Conv2D(192, (1,1), strides = 1,padding='same', name='Block-C_branch_0')(x)\n","        branch_1 = Conv2D(192, (3,1), strides = 1,padding='same', name='Block-C_branch_1_1')(x)\n","        branch_1 = Conv2D(192, (1,3), strides = 1,padding='same', name='Block-C_branch_1_2')(branch_1)\n","        branch_1 = Conv2D(192, (1,1), strides = 1,padding='same', name='Block-C_branch_1_3')(branch_1)\n","        branches = [branch_0, branch_1]\n","\n","    else:\n","        raise ValueError('Unknown Inception-ResNet block type. '\n","                         'Expects \"block35\", \"block17\" or \"block8\", '\n","                         'but got: ' + str(block_type))\n","\n","    mixed = Concatenate(axis=3)(branches)\n","\n","    '''確保輸入跟輸出深度相同'''\n","    up = Conv2d_bn(mixed,K.shape(x)[3],1,activation=None)\n","\n","    '''導入殘差結構，並給予權重'''\n","    x = Lambda(lambda inputs, scale: inputs[0]+inputs[1] * scale, ##提示inputs[0]、inputs[1]\n","               output_shape= K.shape(x)[1:],\n","               arguments={'scale': scale},)([x,up])\n","\n","    if activation is not None:\n","        x = Activation(activation)(x)\n","    return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"id":"wv-ni8GpJbaU","outputId":"89fa224e-9cbf-4b13-dee6-17d6494d079f","executionInfo":{"status":"error","timestamp":1724166204622,"user_tz":-480,"elapsed":439,"user":{"displayName":"TMU陳筱蓁","userId":"00816295719701166481"}}},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'keras.backend' has no attribute 'shape'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-9e722ea30103>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minception_resnet_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Incpetion_Block-A'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-39-ba435d39d3ef>\u001b[0m in \u001b[0;36minception_resnet_block\u001b[0;34m(x, scale, block_type, activation)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m'''確保輸入跟輸出深度相同'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2d_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m'''導入殘差結構，並給予權重'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'keras.backend' has no attribute 'shape'"]}],"source":["img_input = Input(shape=(224,224,32))\n","x=inception_resnet_block(img_input, 0.1, 'Incpetion_Block-A', activation='relu')\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"HOBuOAjOJbab"},"source":["## 測試"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T-igNjppJbad","outputId":"0455b644-5456-4145-d719-3878348aa4cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor(\"activation_46/Relu:0\", shape=(?, 224, 224, 32), dtype=float32)\n"]}],"source":["img_input = Input(shape=(224,224,32))\n","x=inception_resnet_block(img_input, 0.1, 'Incpetion_Block-A', activation='relu')\n","print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V7otKKZWJbah","outputId":"bca7b98f-b8ab-4318-d884-77c8ee7c7fa8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor(\"activation_51/Relu:0\", shape=(?, 224, 224, 32), dtype=float32)\n"]}],"source":["img_input = Input(shape=(224,224,32))\n","x=inception_resnet_block(img_input, 0.1, 'Incpetion_Block-B', activation='relu')\n","print(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RjxCkTlHJbal","outputId":"462b602c-2a47-4790-eff4-13c875aba275"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor(\"activation_56/Relu:0\", shape=(?, 224, 224, 32), dtype=float32)\n"]}],"source":["img_input = Input(shape=(224,224,32))\n","x=inception_resnet_block(img_input, 0.1, 'Incpetion_Block-C', activation='relu')\n","print(x)"]},{"cell_type":"markdown","metadata":{"id":"UYD4kS0BJbao"},"source":["## 嘗試導入Inception Block到 Vgg_Inception中"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FEe8WW2qJbap"},"outputs":[],"source":["def VGG16_ResNet_Inception(include_top=True,input_tensor=None, input_shape=(224,224,1),\n","          pooling='max',classes=1000):\n","\n","    img_input = Input(shape=input_shape)\n","\n","    x = Conv2d_bn(img_input,64, (3, 3), activation='relu', padding='same', name='block1_conv1')\n","    x = Conv2d_bn(x,64, (3, 3), activation='relu', padding='same', name='block1_conv2')\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n","\n","    # Block 2\n","    x = Conv2d_bn(x,128, (3, 3), activation='relu', padding='same', name='block2_conv1')\n","    x = Conv2d_bn(x,128, (3, 3), activation='relu', padding='same', name='block2_conv2')\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n","\n","    # Block 3\n","    x = InceptionV1_block(x, ((64,), (96,128), (16,32), (32,)), 3, 'Block_1')\n","    x = InceptionV1_block(x, ((64,), (96,128), (16,32), (32,)), 3, 'Block_2')\n","    x = InceptionV1_block(x, ((64,), (96,128), (16,32), (32,)), 3, 'Block_3')\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n","\n","    # Block 4\n","    x = Conv2d_bn(x,512, (3, 3), activation='relu', padding='same', name='block4_conv1')\n","    x = Conv2d_bn(x,512, (3, 3), activation='relu', padding='same', name='block4_conv2')\n","    x = Conv2d_bn(x,512, (3, 3), activation='relu', padding='same', name='block4_conv3')\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n","\n","    # Block 5\n","    #為什麼要加InceptionV3_block 原因?\n","    x =InceptionV3_block(x, ((128,), (192,256), (32,64), (64,)), 3, 'Block_4')\n","    x =InceptionV3_block(x, ((128,), (192,256), (32,64), (64,)), 3, 'Block_5')\n","    x =InceptionV3_block(x, ((128,), (192,256), (32,64), (64,)), 3, 'Block_6')\n","    x =MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n","\n","    if include_top:\n","        # Classification block\n","        x = Flatten(name='flatten')(x)\n","        x = Dense(4096, activation='relu', name='fc1')(x)\n","        x = Dense(4096, activation='relu', name='fc2')(x)\n","        x = Dense(classes, activation='softmax', name='predictions')(x)\n","    else:\n","       #可以提醒學員為什麼要加avg或是max\n","        if pooling == 'avg':\n","            x = GlobalAveragePooling2D()(x)\n","        elif pooling == 'max':\n","            x = GlobalMaxPooling2D()(x)\n","\n","    inputs = img_input\n","    # Create model.\n","    model = Model(inputs, x, name='vgg16')\n","\n","\n","    return model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mQufg4jFJbas","colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"status":"error","timestamp":1724166559139,"user_tz":-480,"elapsed":381,"user":{"displayName":"TMU陳筱蓁","userId":"00816295719701166481"}},"outputId":"ec2fc18b-193d-4f8e-e490-7bbe392e00d5"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'InceptionV1_block' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-a5251bbf8ed4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16_ResNet_Inception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-51-906bc05cc1d7>\u001b[0m in \u001b[0;36mVGG16_ResNet_Inception\u001b[0;34m(include_top, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Block 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInceptionV1_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Block_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInceptionV1_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Block_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInceptionV1_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Block_3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'InceptionV1_block' is not defined"]}],"source":["model = VGG16_ResNet_Inception(include_top=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e3WfMLiYJbav"},"outputs":[],"source":["model.summary()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":0}